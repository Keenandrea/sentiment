{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Keenandrea/sentiment/blob/master/sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-7vjEQ83joZ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# User Sentiment\n",
        "\n",
        "---\n",
        "\n",
        "This Colabook will explore words and their ability to define sentiment. Sentiment is easier displayed in-person than interpreted through text. One challenge that rears its ugly head into the constant digital messaging of our modern communication is how to recognize the sentiment of someone using this form of communication. Many approaches have been taken, in recent years, emails have included exclamation points instead of periods because the exclamation point, although originally used as a device to exclaim, looks much friendlier than a full-stop period. Emojis are another valuable method of sentiment communication between texts. That being said, wouldn't it be nice to receive a text message full of words and words alone, a text message that could be translated as facetious, sarcastic, rude, or coy joking, depending on which way the receiver interpreted it, and immediately, if confused, have an app that scans the message and returns the correct sentiment of the sender? Although this project does not cover the all-encompassing spectrum of human sentiment, we'll be employing methods of binary classification on a large dataset of tweets from multiple different users to determine whether that user's tweet was of positive or negative sentiment.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRld-3lRMX7z",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## De Rigueur Libraries\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCQ7DkAxA7yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import gensim\n",
        "\n",
        "import csv\n",
        "import nltk\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import random\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.regularizers import L1L2\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import pickle\n",
        "import re\n",
        "from collections import Counter\n",
        "from string import punctuation\n",
        "import tweepy\n",
        "from tweepy import OAuthHandler\n",
        "import json\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "pd.set_option('display.max_colwidth', 100)\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6FmnfW7MWiJ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkyMyjZPV38T",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Kaggle Meets Colab\n",
        "\n",
        "---\n",
        "\n",
        "Want to access Kaggle data from Colab? Course you do. So: login to Kaggle. Next tab to: [ your profile -> my account -> more -> account -> create new API token ]. And one kaggle.json should start downloading. Then: \n",
        "\n",
        "Open kaggle.json. Copy \"YOUR_USERNAME\" and ”SOME-BETY-BETY-LONG-STRING” from line { “username” : ”YOUR-USER-NAME”, ”key” : ”SOME-BETY-BETY-LONG-STRING” }. Paste each according to the cell below: \n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDQZg6bGH62Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"keenandrea\"\n",
        "os.environ['KAGGLE_KEY'] = \"df347d3b581e5cad8bda11ebdd72e9bb\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhV8LOk_Z0dW",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Presto. You've got all the kaggle datasets neatly before you. Seeing is believing? Sure. Run the cell below:\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD990VgYaWbj",
        "colab_type": "code",
        "outputId": "10405f39-18fc-4900-89af-1d958a224a4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "!kaggle datasets list -s sentiment"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                                    title                                          size  lastUpdated          downloadCount  \n",
            "-----------------------------------------------------  --------------------------------------------  -----  -------------------  -------------  \n",
            "crowdflower/twitter-airline-sentiment                  Twitter US Airline Sentiment                    3MB  2019-10-16 00:04:05          33061  \n",
            "harriken/emoji-sentiment                               Emoji sentiment                                12MB  2017-10-01 09:56:54           2197  \n",
            "bittlingmayer/amazonreviews                            Amazon Reviews for Sentiment Analysis         493MB  2019-11-18 02:50:34          19116  \n",
            "kazanova/sentiment140                                  Sentiment140 dataset with 1.6 million tweets   81MB  2017-09-13 22:43:19          20951  \n",
            "crowdflower/first-gop-debate-twitter-sentiment         First GOP Debate Twitter Sentiment              2MB  2019-11-17 21:18:37          14841  \n",
            "arkhoshghalb/twitter-sentiment-analysis-hatred-speech  Twitter Sentiment Analysis                      2MB  2019-01-06 05:00:19           1612  \n",
            "marklvl/sentiment-labelled-sentences-data-set          Sentiment Labelled Sentences Data Set         326KB  2018-04-24 21:20:20           3521  \n",
            "cjroth/chronist                                        Emotion, Aging, and Sentiment Over Time        13MB  2017-02-12 22:44:03           1226  \n",
            "welkin10/airline-sentiment                             Airline sentiment                               1MB  2018-05-27 07:23:18            477  \n",
            "taniaj/australian-election-2019-tweets                 Australian Election 2019 Tweets                29MB  2019-05-21 09:41:38           3356  \n",
            "rtatman/sentiment-lexicons-for-81-languages            Sentiment Lexicons for 81 Languages             2MB  2017-09-13 19:59:05           5011  \n",
            "iarunava/imdb-movie-reviews-dataset                    IMDB Movie Reviews Dataset                    224MB  2018-07-25 08:11:18          11561  \n",
            "thomasseleck/emoji-sentiment-data                      Emoji sentiment data                           33KB  2019-03-01 22:41:15            279  \n",
            "sonaam1234/sentimentdata                               Sentiment Analysis Dataset                    947KB  2019-11-18 02:41:47           2001  \n",
            "mksaad/arabic-sentiment-twitter-corpus                 Arabic Sentiment Twitter Corpus                 2MB  2019-04-13 18:07:18            506  \n",
            "yelp-dataset/yelp-dataset                              Yelp Dataset                                    4GB  2019-02-05 19:09:56          45050  \n",
            "sid321axn/amazon-alexa-reviews                         Amazon Alexa Reviews                          164KB  2018-07-31 17:45:14           6512  \n",
            "rahulin05/sentiment-labelled-sentences-data-set        Sentiment Labelled Sentences Data Set          80KB  2017-08-31 14:07:09           1034  \n",
            "rtatman/thai-sentiment-analysis-toolkit                Thai Sentiment Analysis Toolkit                 8KB  2017-09-06 20:32:55            526  \n",
            "rtatman/german-sentiment-analysis-toolkit              German Sentiment Analysis Toolkit              84KB  2017-08-15 22:54:27            740  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EdTHt5_ahui",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Now: shop the dataset you want. Once that dataset** is found, run command !kaggle datasets download -d NAME_OF_YOUR_DESIRED_DATASET -p /content. For instance, I want kazanova/sentiment140. That's point [1,4] on the list above, which is column one, row four. That's what I want. This is how I get it:\n",
        "\n",
        "**[Footnote]: alternatively, run !kaggle datasets list, to display the whole kit-and-kaboodle. What you see one cell up is a filtering option to search kaggle datasets with substring [-s] sentiment [sentiment].  \n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVArQjqkbY20",
        "colab_type": "code",
        "outputId": "c7e8e7bc-f3ee-4df2-cc75-86a064c39edd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "!kaggle datasets download -d kazanova/sentiment140 -p /content"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading sentiment140.zip to /content\n",
            " 96% 78.0M/80.9M [00:02<00:00, 24.9MB/s]\n",
            "100% 80.9M/80.9M [00:02<00:00, 28.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LyRmHCLbiuD",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Last things last, you've got to unzip the dataset, and then turn it loose on your Colabook. Easy peasy.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX5pEOvHbe4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q sentiment140.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqBVyABsMLmW",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdKD0Puj8pcn",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Tweet Sentiment\n",
        "\n",
        "---\n",
        "\n",
        "In this next part we're going to parse, clean, embed, analyze, train, and obtain sentiment predictions for the *sentiment140* kaggle dataset using the most frequent words in the text corpus as feature columns.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AE_7f0fpcrjF",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Input Features\n",
        "\n",
        "---\n",
        "\n",
        "There are six feature columns in the twitter sentiment dataset. The tweets are cut evenly down the middle. Half of them are of positive sentiment, the other half negative. The sentiment dataset was pulled from Kaggle through a colab notebook. The dataset was made of six feature columns, that is: 'label', 'id', 'date', 'flag', 'user', and 'text'. To clear the fluff, we'll remove three feature columns that contribute very little to our purpose, namely: id, flag, and user. Id is tacit upon creating our Pandas dataframe, flag is the query, user is needless since we aren't considering who authored the tweet, and, finally, date is of little care to us as well, since we will not be attempting any time-series analysis. The only two feature columns truly necessary for our purpose are label and text as our example input-output pairs for our supervised learning task. \n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ_i_Mb5umbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweet_file = 'training.1600000.processed.noemoticon.csv'\n",
        "cleaning = '@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+'\n",
        "features = ['label','id','date','flag','user','text']\n",
        "encoding = 'ISO-8859-1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuHLTl1Tbc3e",
        "colab_type": "code",
        "outputId": "02ec2c58-aa85-4c22-8fb5-c39c57408bbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "df = pd.read_csv(tweet_file,names=features,encoding=encoding)\n",
        "df.head(2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by texting it... and might cry as a result  School to...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  ...                                                                                                 text\n",
              "0      0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Thi...\n",
              "1      0  ...  is upset that he can't update his Facebook by texting it... and might cry as a result  School to...\n",
              "\n",
              "[2 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj92KJrtnoTl",
        "colab_type": "code",
        "outputId": "94b72936-1ad5-4a55-d917-aeda132dd5a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print('Dataset size of',df.shape[0],'rows and',df.shape[1],'columns')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset size of 1600000 rows and 6 columns\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8W7Zmm4n7di5",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Reducing Input Features\n",
        "\n",
        "---\n",
        "\n",
        "### Dropping Feature Columns\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ormL0oVneLlw",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "To clear the fluff, we'll remove three feature columns that contribute very little to our purpose, namely: id, flag, and user. Id is tacit upon creating our Pandas dataframe, flag is the query, user is needless since we aren't considering who authored the tweet, and, finally, date is of little care to us as well, since we will not be attempting any time-series analysis. The only two feature columns truly necessary for our purpose are label and text as our example input-output pairs for our supervised learning task.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSS8oPgqzo5D",
        "colab_type": "code",
        "outputId": "d48b22dd-5175-43a1-c065-9921a0fcb391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "df = df.drop(columns=['id','date','flag','user'])\n",
        "df.head(2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by texting it... and might cry as a result  School to...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                                                                                 text\n",
              "0      0  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Thi...\n",
              "1      0  is upset that he can't update his Facebook by texting it... and might cry as a result  School to..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpEBpYziOfAf",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Feature Importance\n",
        "\n",
        "---\n",
        "\n",
        "### Importance of Label Column\n",
        "\n",
        "---\n",
        "\n",
        "Our label column is binary. Rows with 0 indicate tweets with negative sentiment, while rows with 4 indicate tweets with positive sentiment. This feature column is important because it gives face to the binary classification problem our model will be facing.\n",
        "\n",
        "\n",
        "The plot below shows the label feature column of our dataframe is split evenly between tweets recognized as positive, and tweets recognized as negative. \n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfWiaLFLfq4D",
        "colab_type": "code",
        "outputId": "81447b12-9848-4cca-b8bf-dd013d11ad5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "sns.countplot(x='label',data=df)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff662ea52e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEDCAYAAAAbTVIhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u5-TQ5FVNUZ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Importance of Text Column\n",
        "\n",
        "---\n",
        "\n",
        "The text feature column is tricky. It's the only input column we both have and need to perform our binary classification. The obstacle deals with somehow withdrawing the important features from the text feature column and employing them for a model that is able to predict tweet sentiment given a set of words. \n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AAlGlj1x5TCs"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "The most frequent words do not matter much with regard to user sentiment. Many of them are grammatical need-bes placed within the text to signify other, more important parts of speech that do express sentiment, such as nouns, adjectives, and verbs.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNYATIZ4mBCD",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "The solution here is to remove those frivolities. We'll use nltk's stopwords function to do this. The function contains a pre-defined list of English words that would be considered under our umbrella of frivolities.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toea-ZUOkLG_",
        "colab_type": "code",
        "outputId": "2d947e2a-4a2f-4191-a0dd-9840c0303f8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words=stopwords.words(\"english\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKuF453wuvmC",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Cleaning The Tweets\n",
        "\n",
        "---\n",
        "\n",
        "Next we'll want to reduce the extraneous characters over-crowding the language used in each tweet, thereby allowing the model an easier go at identifying sentiment. Mentions, or, tagging a user in a post with the @ character exemplifies the type of foofaraw we'll be removing. Not only that, but we'll also remove https://, or, hyperlinks from our feature column, among other things, to ensure, as stated, that any noise our model may encounter when embedding and analyzing the content of a tweet is reduced as much as we can possibly reduce it.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPC0idihkjr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus=[]\n",
        "for i in range(0,len(df)):\n",
        "    review=re.sub('@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+',' ',df['text'][i])\n",
        "    review=review.lower()\n",
        "    review=review.split()\n",
        "    review=[word for word in review if not word in stop_words]\n",
        "    review=' '.join(review)\n",
        "    corpus.append(review)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC-2fLTZlq7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.text=corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGEXWpEQltyX",
        "colab_type": "code",
        "outputId": "75414990-7fda-4d72-cc4f-7ea486b9a941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "df.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>awww bummer shoulda got david carr third day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>upset update facebook texting might cry result school today also blah</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                                                   text\n",
              "0      0                           awww bummer shoulda got david carr third day\n",
              "1      0  upset update facebook texting might cry result school today also blah"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbmzZQYbIgCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uWe1AqOIuys",
        "colab_type": "code",
        "outputId": "bfc285a8-3802-4e78-bd1e-4cabd1f06f68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>good</th>\n",
              "      <th>day</th>\n",
              "      <th>like</th>\n",
              "      <th>today</th>\n",
              "      <th>work</th>\n",
              "      <th>love</th>\n",
              "      <th>lol</th>\n",
              "      <th>time</th>\n",
              "      <th>know</th>\n",
              "      <th>really</th>\n",
              "      <th>see</th>\n",
              "      <th>night</th>\n",
              "      <th>still</th>\n",
              "      <th>well</th>\n",
              "      <th>new</th>\n",
              "      <th>want</th>\n",
              "      <th>think</th>\n",
              "      <th>home</th>\n",
              "      <th>thanks</th>\n",
              "      <th>oh</th>\n",
              "      <th>much</th>\n",
              "      <th>miss</th>\n",
              "      <th>need</th>\n",
              "      <th>feel</th>\n",
              "      <th>hope</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  good  day  like  today  work  ...  oh  much  miss  need  feel  hope\n",
              "0      0     0    0     0      0     0  ...   0     0     0     0     0     0\n",
              "1      0     0    0     0      0     0  ...   0     0     0     0     0     0\n",
              "2      1     0    0     0      0     0  ...   0     0     0     0     0     0\n",
              "3      1     0    0     0      0     0  ...   0     0     0     1     0     0\n",
              "4      0     0    0     0      0     0  ...   0     0     0     0     0     0\n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbyuYAYXJ60J",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "We replace all the 4s in our label column with 1s, to have it represent something more binarily classifiable.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRwCykcrJPlw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.label.replace({4:1},inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3EC_S9-5qpk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "We'll create an array of our choice words. These words are in the top-75 most frequent of our text corpus, after the text was cleaned and the stopwords removed. \n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCpGQg3fOtJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_25 = ['good','day','like','today','work',\n",
        "          'love','lol','time','know','really',\n",
        "          'see','night','still','well','new',\n",
        "          'want','think','home','thanks','oh',\n",
        "          'much','miss','need','feel','hope',\n",
        "          'back','haha','feel','sad','fun',\n",
        "          'wish','sleep','right','bad','would',\n",
        "          'happy','sorry','tonight','come','make',\n",
        "          'though','nice','better','watching','yeah',\n",
        "          'wait','bed','week','school','people']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIQmQNFY6AsW",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Word by word, we'll create feature columns that contain the count of each word in each tweet.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RlbfEa4N1LW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_frequency(word):\n",
        "  df[word] = df['text'].str.count(word)\n",
        "\n",
        "for i in range(0,25,1):\n",
        "  word_frequency(top_25[i])\n",
        "\n",
        "df = df.drop(columns=['text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b_q-jI3i7oOG"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Word embeddings are vector representations of any particular word. The technique we'll use to embed our tweets'll be a popular one known as Word2Vec. First we'll declare parameters for the Word2Vec model, then we'll build the model, train the model, and lastly run some tests on the results to see if we have what we want from the model.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwB260rhjCqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "documents = [text.split() for text in train.text]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFDBplxijWiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v_model = gensim.models.word2vec.Word2Vec(size=300, \n",
        "                                            window=7, \n",
        "                                            min_count=10, \n",
        "                                            workers=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDi-uOAQjo44",
        "colab_type": "code",
        "outputId": "f6f2be12-387b-4933-f71d-56e121415261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "w2v_model.build_vocab(documents)\n",
        "words = w2v_model.wv.vocab.keys()\n",
        "vocab_size = len(words)\n",
        "print(\"Size of model vocab:\", vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of model vocab: 30413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umiXbSjCj-2m",
        "colab_type": "code",
        "outputId": "d505a63e-210c-447c-d810-ccde987b5c77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "w2v_model.train(documents, total_examples=len(documents), epochs=30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(246692269, 276798180)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3wuMbMM2ET0",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Now, with the model trained, we'll use gensim's most_similar function to find the top-N most similar words. Positive words will contribute positively towards the similarity, negative words contribute negatively. We'll pass this function to a few of the most frequent words in our tweet feature column that will shortly be converted into individual feature columns, appended to the dataframe, and reviewed to assist predictions.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wQWbssq0Qd8",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Our Word2Vec model is making some fairly accurate similarity predictions of a word. What this tells us is that our words have been embedded. \n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2MlPbdxowL7",
        "colab_type": "code",
        "outputId": "fbef83a3-9cb1-4721-b8ac-c5568905ecb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "w2v_model.wv.most_similar(\"day\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('weekend', 0.6777357459068298),\n",
              " ('week', 0.6125987768173218),\n",
              " ('time', 0.5857556462287903),\n",
              " ('dayy', 0.5758532881736755),\n",
              " ('morning', 0.5317856073379517),\n",
              " ('today', 0.5113763213157654),\n",
              " ('sunday', 0.5012823939323425),\n",
              " ('evening', 0.495885968208313),\n",
              " ('night', 0.49416500329971313),\n",
              " ('afternoon', 0.4936937987804413)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy9Om2DQozMX",
        "colab_type": "code",
        "outputId": "7109eef8-1165-4db3-a369-eeb85f05ef04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "w2v_model.wv.most_similar(\"like\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('liek', 0.48944374918937683),\n",
              " ('weird', 0.4865761399269104),\n",
              " ('bad', 0.43718475103378296),\n",
              " ('stalkerish', 0.4228995740413666),\n",
              " ('inadequate', 0.41016289591789246),\n",
              " ('better', 0.408244252204895),\n",
              " ('lik', 0.40413233637809753),\n",
              " ('unloved', 0.4005945920944214),\n",
              " ('familiar', 0.39740145206451416),\n",
              " ('helpless', 0.38819360733032227)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3DtHpD5pBYL",
        "colab_type": "code",
        "outputId": "1d3de52f-b8c6-4bcd-9852-611365ffcc48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "w2v_model.wv.most_similar(\"oh\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ohh', 0.5547873973846436),\n",
              " ('ohhh', 0.5268933773040771),\n",
              " ('ah', 0.49437540769577026),\n",
              " ('ohhhh', 0.4882204532623291),\n",
              " ('aw', 0.4176540970802307),\n",
              " ('ahh', 0.38989633321762085),\n",
              " ('oooh', 0.38025906682014465),\n",
              " ('fargo', 0.3794403672218323),\n",
              " ('nuh', 0.35429030656814575),\n",
              " ('sakes', 0.35300877690315247)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjyM8u_0pAB4",
        "colab_type": "code",
        "outputId": "4e4d27a8-c209-4b9e-c0f2-aa906d4ae446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "w2v_model.wv.most_similar(\"lol\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('lmao', 0.7650360465049744),\n",
              " ('haha', 0.7491662502288818),\n",
              " ('hahaha', 0.6460617184638977),\n",
              " ('u', 0.5969237089157104),\n",
              " ('hehe', 0.5581870675086975),\n",
              " ('cuz', 0.5430053472518921),\n",
              " ('lmfao', 0.5379681587219238),\n",
              " ('hahah', 0.5165081024169922),\n",
              " ('yea', 0.5041918754577637),\n",
              " ('lmaoo', 0.49686700105667114)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_Htia2lS2Ds",
        "colab_type": "code",
        "outputId": "fd2ea833-919c-48cc-fb0c-159e21969897",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "w2v_model.wv.most_similar(\"miss\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('misses', 0.6024397611618042),\n",
              " ('missing', 0.5952507257461548),\n",
              " ('missin', 0.5479378700256348),\n",
              " ('misss', 0.47836437821388245),\n",
              " ('love', 0.4175484776496887),\n",
              " ('misssss', 0.3966166079044342),\n",
              " ('missss', 0.3932454586029053),\n",
              " ('fun', 0.3825644254684448),\n",
              " ('leaving', 0.3809747099876404),\n",
              " ('homesick', 0.37619727849960327)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgWVFMTQS4-2",
        "colab_type": "code",
        "outputId": "05e5f2af-b636-4ed8-b584-435598b76b40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "w2v_model.wv.most_similar(\"need\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('needs', 0.7002875804901123),\n",
              " ('want', 0.6106590628623962),\n",
              " ('needa', 0.539360761642456),\n",
              " ('gotta', 0.5235423445701599),\n",
              " ('trying', 0.5206313133239746),\n",
              " ('wanna', 0.4795724153518677),\n",
              " ('wants', 0.4718064069747925),\n",
              " ('needing', 0.45453277230262756),\n",
              " ('wanting', 0.4053877592086792),\n",
              " ('tryin', 0.3966308534145355)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyVmLpfaUUG1",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Once a list of the most frequent words in our text corpus has been selected by those words that seem most interesting to our purpose, we'll make out of each word a feature column whose rows contain the frequency count of that word in the text of each tweet.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0kCYrtkUyVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(x_train.iloc[:,0])\n",
        "plt.ylabel('good')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_train.iloc[:,1])\n",
        "plt.ylabel('day')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_train.iloc[:,2])\n",
        "plt.ylabel('like')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_train.iloc[:,3])\n",
        "plt.ylabel('today')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_train.iloc[:,4])\n",
        "plt.ylabel('work')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_train.iloc[:,5])\n",
        "plt.ylabel('love')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_train.iloc[:,6])\n",
        "plt.ylabel('lol')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_train.iloc[:,7])\n",
        "plt.ylabel('time')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_train.iloc[:,8])\n",
        "plt.ylabel('know')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_train.iloc[:,9])\n",
        "plt.ylabel('really')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_train.iloc[:,10])\n",
        "plt.ylabel('see')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_train.iloc[:,11])\n",
        "plt.ylabel('night')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_train.iloc[:,12])\n",
        "plt.ylabel('still')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_train.iloc[:,13])\n",
        "plt.ylabel('well')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_train.iloc[:,14])\n",
        "plt.ylabel('new')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_train.iloc[:,15])\n",
        "plt.ylabel('want')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GcMakA2XiCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(x_validate.iloc[:,0])\n",
        "plt.ylabel('good')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_validate.iloc[:,1])\n",
        "plt.ylabel('day')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_validate.iloc[:,2])\n",
        "plt.ylabel('like')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_validate.iloc[:,3])\n",
        "plt.ylabel('today')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_validate.iloc[:,4])\n",
        "plt.ylabel('work')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_validate.iloc[:,5])\n",
        "plt.ylabel('love')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_validate.iloc[:,6])\n",
        "plt.ylabel('lol')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_validate.iloc[:,7])\n",
        "plt.ylabel('time')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_validate.iloc[:,8])\n",
        "plt.ylabel('know')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_validate.iloc[:,9])\n",
        "plt.ylabel('really')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_validate.iloc[:,10])\n",
        "plt.ylabel('see')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_validate.iloc[:,11])\n",
        "plt.ylabel('night')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_validate.iloc[:,12])\n",
        "plt.ylabel('still')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_validate.iloc[:,13])\n",
        "plt.ylabel('well')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_validate.iloc[:,14])\n",
        "plt.ylabel('new')\n",
        "plt.show()\n",
        "\n",
        "plt.hist(x_validate.iloc[:,15])\n",
        "plt.ylabel('want')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QzpVLPg6YQy",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "The dataframe is split between train, test, and validate sets.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4e-McNkKQW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_validate = df.iloc[:240000,1:26]\n",
        "y_validate = df.iloc[:240000,0]\n",
        "\n",
        "x_train = df.iloc[240000:1200000,1:26]\n",
        "y_train = df.iloc[240000:1200000,0]\n",
        "\n",
        "x_test = df.iloc[1200000:,1:26]\n",
        "y_test = df.iloc[1200000:,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1pqNsSb6dUu",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "The train and validate sets are normalized.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxGo1LFlnuSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "std_scale = preprocessing.StandardScaler().fit(x_train)\n",
        "x_train_norm = std_scale.transform(x_train)\n",
        "training_norm_col = pd.DataFrame(x_train_norm, index=x_train.index, columns=x_train.columns) \n",
        "x_train.update(training_norm_col)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKryuurSseov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY-n2xkIpmEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "std_scale = preprocessing.StandardScaler().fit(x_validate)\n",
        "x_validate_norm = std_scale.transform(x_validate)\n",
        "validate_norm_col = pd.DataFrame(x_validate_norm, index=x_validate.index, columns=x_validate.columns) \n",
        "x_validate.update(validate_norm_col)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbaHUm_Vp0Jl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_validate.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isQMt17v25Ew",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Linear Regression Model\n",
        "\n",
        "---\n",
        "\n",
        "To compare Linear Regression model applications against Logistic Regression applications, we'll use sklean's Linear and Logistic Regression built-in models and evaluate them by R-squared and RMSE metrics.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lwHYFOm2rq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "lin_regression = LinearRegression()\n",
        "_ = lin_regression.fit(pd.DataFrame(x_train),y_train)\n",
        "lin_y_pred_1 = lin_regression.predict(pd.DataFrame(x_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNM_8IjhLGZZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6a3deaf4-d95b-4b51-af0c-91e5ddc800f4"
      },
      "source": [
        "linreg = LinearRegression()\n",
        "linreg.fit(x_train, y_train)\n",
        "y_pred = linreg.predict(x_validate)\n",
        "acc_log = round(linreg.score(x_train, y_train) * 100, 2)\n",
        "acc_log"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EDnWskR3f1D",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Logistic Regression Model\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi-eiQVT3lsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "log_regression = LogisticRegression(solver='lbfgs')\n",
        "_ = log_regression.fit(pd.DataFrame(x_train),y_train)\n",
        "y_pred = log_regression.predict_proba(pd.DataFrame(x_train))\n",
        "log_y_pred_1 = [item[1] for item in y_pred]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovzHhzRJK093",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "b4e39f37-ac10-4161-8607-b4cb7afa419d"
      },
      "source": [
        "logreg = LogisticRegression()\n",
        "logreg.fit(x_train, y_train)\n",
        "y_pred = logreg.predict(x_validate)\n",
        "acc_log = round(logreg.score(x_train, y_train) * 100, 2)\n",
        "acc_log"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58.73"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "852LW3Pq63Xd",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Accuracy Metrics\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWoxFn396F2S",
        "colab_type": "code",
        "outputId": "907009dd-42fb-459d-e4c8-d7960c7b3b73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "print(\"Linear Regression R2:\",r2_score(y_train,lin_y_pred_1))\n",
        "print(\"Logistic Regression R2:\",r2_score(y_train,log_y_pred_1))\n",
        "print(\"Linear Regression RMSE: \", mean_squared_error(y_train, lin_y_pred_1))\n",
        "print(\"Logistic Regression RMSE: \", mean_squared_error(y_train, log_y_pred_1))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear Regression R2: 0.072545906166119\n",
            "Logistic Regression R2: 0.07540952582770022\n",
            "Linear Regression RMSE:  0.23186328771445316\n",
            "Logistic Regression RMSE:  0.23114738352694428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fakcUIYyKo8L",
        "colab_type": "code",
        "outputId": "df40bb1f-7f07-448f-ad63-0d7d2ba69c10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "model = Sequential()  \n",
        "model.add(Dense(64,input_dim=25,activation='relu'))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(8,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "print(model.summary())"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_20 (Dense)             (None, 64)                1664      \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 8)                 520       \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 6,353\n",
            "Trainable params: 6,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw158zD208dk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsVc81yi-L5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(x_train, y_train, epochs=15, batch_size=100, validation_data=(x_validate, y_validate))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78xAAEiu98Xk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Evaluating the model on the training data gives us the following results.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Duf0W-ZZ-FgY",
        "colab_type": "code",
        "outputId": "16d0d08a-e96b-43ee-ad4e-5f0b897c0fb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "scores = model.evaluate(x_train, y_train)\n",
        "print(model.metrics_names)\n",
        "print(scores)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "960000/960000 [==============================] - 48s 51us/step\n",
            "['loss', 'acc']\n",
            "[0.6491343979736169, 0.5910583333333334]\n",
            "\n",
            "acc: 59.11%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5uN_Izi-B4P",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "Evaluating the model on the validation data gives us the following results.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmtU3VF_-Ios",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "a424039c-463f-4cc7-d7c4-ef6126489b45"
      },
      "source": [
        "scores = model.evaluate(x_validate, y_validate)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "240000/240000 [==============================] - 12s 50us/step\n",
            "\n",
            "acc: 59.10%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTSwin0j-tFB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "b9ffe54c-f8d6-4fcc-b4a0-75eee17a48c9"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "prediction = model.predict(x_validate)\n",
        "accuracy = accuracy_score(y_validate, prediction.round())\n",
        "precision = precision_score(y_validate, prediction.round())\n",
        "recall = recall_score(y_validate, prediction.round())\n",
        "f1score = f1_score(y_validate, prediction.round())\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
        "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
        "print(\"F1-score: %.2f\" % (f1score))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 59.10%\n",
            "Precision: 56.47%\n",
            "Recall: 80.40%\n",
            "F1-score: 0.66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m10O7eMlNGLl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Machine Learning Algorithms\n",
        "\n",
        "---\n",
        "\n",
        "A last ditch effort. We'll move away from deep learning and revert to machine learning, leveraging several algorithms for our purpose to see if these outperform our network architectures.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZlkPYe0NFkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNVvNxFVNcam",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Support Vector Machines\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khYRUO9WM4OE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "svc = SVC()\n",
        "svc.fit(x_train, y_train)\n",
        "Y_pred = svc.predict(x_validate)\n",
        "acc_svc = round(svc.score(x_train, y_train) * 100, 2)\n",
        "acc_svc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcSjCvYCNhqi",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "### k-Nearest Neighbors\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iR5UgoEMhGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors = 3)\n",
        "knn.fit(x_train, y_train)\n",
        "Y_pred = knn.predict(x_validate)\n",
        "acc_knn = round(knn.score(x_train, y_train) * 100, 2)\n",
        "acc_knn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXCDk1EUNmm8",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Gaussian Naive Bayes\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gk4a-k6MoYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gaussian = GaussianNB()\n",
        "gaussian.fit(x_train, y_train)\n",
        "Y_pred = gaussian.predict(x_validate)\n",
        "acc_gaussian = round(gaussian.score(x_train, y_train) * 100, 2)\n",
        "acc_gaussian"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hivl9GRaNq7F",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "### Perceptron\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vu_xZw8MM9TG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "perceptron = Perceptron()\n",
        "perceptron.fit(x_train, y_train)\n",
        "Y_pred = perceptron.predict(x_validate)\n",
        "acc_perceptron = round(perceptron.score(x_train, y_train) * 100, 2)\n",
        "acc_perceptron"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8VFHMhCNtlB",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "### Linear Support Vector Machines\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zigGUPnuM_TN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear_svc = LinearSVC()\n",
        "linear_svc.fit(X_train, Y_train)\n",
        "Y_pred = linear_svc.predict(X_test)\n",
        "acc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\n",
        "acc_linear_svc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zykkNkEN0m7",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "### Stochastic Gradient Descent\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibajn7XuMsM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd = SGDClassifier()\n",
        "sgd.fit(x_train, y_train)\n",
        "Y_pred = sgd.predict(x_validate)\n",
        "acc_sgd = round(sgd.score(x_train, y_train) * 100, 2)\n",
        "acc_sgd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pPNg-XfN54z",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "### Decision Tree\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD1qn05iMuMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decision_tree = DecisionTreeClassifier()\n",
        "decision_tree.fit(x_train, y_train)\n",
        "Y_pred = decision_tree.predict(x_validate)\n",
        "acc_decision_tree = round(decision_tree.score(x_train, y_train) * 100, 2)\n",
        "acc_decision_tree"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIC2z7ucN9jT",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "### Random Forest\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgpxBTjvMwQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_forest = RandomForestClassifier(n_estimators=100)\n",
        "random_forest.fit(x_train, y_train)\n",
        "Y_pred = random_forest.predict(x_validate)\n",
        "random_forest.score(x_train, y_train)\n",
        "acc_random_forest = round(random_forest.score(x_train, y_train) * 100, 2)\n",
        "acc_random_forest"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XhNO_xvOArx",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "### Comparative Evaluation\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDN9088iM03M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = pd.DataFrame({\n",
        "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
        "              'Random Forest', 'Naive Bayes', 'Perceptron', \n",
        "              'Stochastic Gradient Decent', 'Linear SVC', \n",
        "              'Decision Tree'],\n",
        "    'Score': [acc_svc, acc_knn, acc_log, \n",
        "              acc_random_forest, acc_gaussian, acc_perceptron, \n",
        "              acc_sgd, acc_linear_svc, acc_decision_tree]})\n",
        "models.sort_values(by='Score', ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fkh9xX_T_K6N",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Let's check this out. Let's evaluate. Accuracy, for starters, is not good. Just 9 percent above half right, half wrong. Precision, which refers to the percentage of model results that are relevent, is less. Fifty-six percent of our model results are relevent. No good. Recall, at eighty percent, which refers to the percentage of total relevant results correcly classified by the model, isn't bad, however, considering eighty percent of fifty-six percent of results were correctly classified, it seems nonsensical as well. Finally, F1-score, which, in a nutshell is the measure of our model's accuracy, is 0.66. Evaluation? Words alone, at least the amount we have here, and their frequency within a text corpus, are not enough to predict sentiment.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1LWNMtvAoov",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Future Considerations\n",
        "\n",
        "---\n",
        "\n",
        "Thing is, this is quite an unorthodox approach to solving the text sentiment problem. Most approaches use word embeddings, similar to those discussed earlier. Since ours is a novel approach to the problem, it's moreso experimentation to see whether a new approach will better solve the problem, and, in this case, this sadly is not a better way. \n",
        "\n",
        "We could've seen this coming. From the word embeddings above, it's apparent that one word, such as 'lol' or 'happy' is not the only case to be evaluated. Rather, a word like 'lol' has counterpart words, according to the Word2Vec similarity, such as 'lmao', 'haha', 'hahaha', 'hha', 'hahhah', 'hehe', 'lmfao', 'rofl', 'lolol', 'lmaoo', and many, many others. That's the problem. People do not text with grammatical accuracy. Which leads us to believe, in order to properly define sentiment using a word, we must include all similar cases of that word under one umbrella, a sort of joining together of all similar usage will increase the low number of occurrences in our text corpus and hopefully give the model better predicative capability. \n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    }
  ]
}